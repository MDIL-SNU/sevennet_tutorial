{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MDIL-SNU/sevennet_tutorial/blob/main/CMSS_DFT_2025/Part2_Fine_tuning/2_Fine_tuning.ipynb)"
      ],
      "metadata": {
        "id": "fJTY_VlwiJlC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installation\n",
        "\n",
        "SevenNet can be easily installed via pip."
      ],
      "metadata": {
        "id": "Su0XDjIAVd8y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSDTb2EBPTaA"
      },
      "outputs": [],
      "source": [
        "!pip install sevenn==0.11.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check whether your installation is successful"
      ],
      "metadata": {
        "id": "rXfI6lIFVqW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sevenn.logger import Logger\n",
        "logger = Logger(screen=True)\n",
        "logger.greeting()"
      ],
      "metadata": {
        "id": "tJIqGfP61rFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtain files from github"
      ],
      "metadata": {
        "id": "jTbZu6XCV1oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Jaesun0912/sevennet_tutorial.git\n",
        "\n",
        "prefix = 'sevennet_tutorial/CMSS_DFT_2025/'"
      ],
      "metadata": {
        "id": "BsYrq-dvR4xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirm mounting and directories are successful"
      ],
      "metadata": {
        "id": "r64sDiAMV8ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ase.io import read\n",
        "from ase.visualize import view\n",
        "atoms = read(f'{prefix}/data/600K.extxyz')\n",
        "view(atoms, viewer='x3d')"
      ],
      "metadata": {
        "id": "HvfLokw3WLEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Fine-tuning w/o shift adjustment"
      ],
      "metadata": {
        "id": "BHGuVi1UWgFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's build model from checkpoint.\n",
        "\n",
        "Unlike training from scratch, model weights are read from the values contained in the checkpoint."
      ],
      "metadata": {
        "id": "oyX83JwSwmPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sevenn.util as util\n",
        "\n",
        "\n",
        "model, config = util.model_from_checkpoint(f'{prefix}/pretrained/checkpoint_small.pth')"
      ],
      "metadata": {
        "id": "Jcixw6kxwjrM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's load the dataset.\n",
        "\n",
        "In this case, we will use only 1/4 of the total training set."
      ],
      "metadata": {
        "id": "2VKVUUalwqfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from sevenn.train.graph_dataset import SevenNetGraphDataset\n",
        "\n",
        "\n",
        "data_paths = [f'{prefix}/data/600K.extxyz', f'{prefix}/data/1200K.extxyz']\n",
        "dataset = SevenNetGraphDataset(\n",
        "    cutoff=config['cutoff'], files=data_paths, drop_info=False\n",
        ")\n",
        "num_dataset = len(dataset)\n",
        "num_train = int(num_dataset * 0.25)\n",
        "num_valid = 10\n",
        "\n",
        "dataset = dataset.shuffle()\n",
        "trainset = dataset[:num_train]\n",
        "validset = dataset[num_train:num_train + 10]\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "valid_loader = DataLoader(validset, batch_size=4)"
      ],
      "metadata": {
        "id": "ika75AifWssi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we define hyperparameters for the fine-tuning."
      ],
      "metadata": {
        "id": "DFaMbyvoeUUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import torch.optim.lr_scheduler as scheduler\n",
        "\n",
        "from sevenn.error_recorder import ErrorRecorder\n",
        "from sevenn.train.trainer import Trainer\n",
        "\n",
        "\n",
        "config.update({\n",
        "    'optimizer': 'adam',\n",
        "    'optim_param': {'lr': 0.004},\n",
        "    'scheduler': 'linearlr',\n",
        "    'scheduler_param': {\n",
        "        'start_factor': 1.0, 'total_iters': 10, 'end_factor': 0.0001\n",
        "    },\n",
        "    'is_ddp': False,  # 7net-0 is traied with ddp=True.\n",
        "                      # We override this key False as we won't use it\n",
        "    'loss': 'huber',\n",
        "    'loss_param': {'delta': 0.01},\n",
        "    'force_loss_weight': 0.1,\n",
        "    'stress_loss_weight': 0.01,\n",
        "})\n",
        "trainer = Trainer.from_config(model, config)\n",
        "\n",
        "train_recorder = ErrorRecorder.from_config(config)\n",
        "valid_recorder = deepcopy(train_recorder)"
      ],
      "metadata": {
        "id": "jDikd_FKX-DS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following script will fine-tune SevenNet-0-small with small epoch.\n",
        "\n",
        "After training, we can save fine-tuned model to the checkpoint."
      ],
      "metadata": {
        "id": "HXCBgPc6ejn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "from sevenn.logger import Logger\n",
        "\n",
        "\n",
        "valid_best = float('inf')\n",
        "total_epoch = 10\n",
        "\n",
        "# As error recorder is long, let's use sevennet_logger for pretty print\n",
        "# It is similar to outputs when using sevennet with terminal.\n",
        "with Logger(filename='log.sevenn', screen=True) as logger:\n",
        "  logger.greeting()  # prints ascii logo\n",
        "  for epoch in range(total_epoch):\n",
        "    logger.timer_start('epoch')\n",
        "    # trainer scans whole data from given loader,\n",
        "    # and updates error recorder with outputs.\n",
        "    trainer.run_one_epoch(\n",
        "        train_loader, is_train=True, error_recorder=train_recorder\n",
        "    )\n",
        "    trainer.run_one_epoch(\n",
        "        valid_loader, is_train=False, error_recorder=valid_recorder\n",
        "    )\n",
        "    trainer.scheduler_step()\n",
        "    train_err = train_recorder.epoch_forward()  # return averaged error & reset\n",
        "    valid_err = valid_recorder.epoch_forward()\n",
        "    logger.bar()\n",
        "    logger.writeline(\n",
        "        f'Epoch {epoch+1}/{total_epoch}  Learning rate: {trainer.get_lr()}'\n",
        "    )\n",
        "    logger.write_full_table([train_err, valid_err], ['Train', 'Valid'])\n",
        "    logger.timer_end('epoch', message=f'Epoch {epoch+1} elapsed')\n",
        "\n",
        "trainer.write_checkpoint(\n",
        "    f'{prefix}/checkpoint_fine_tuned.pth', config=config, epoch=total_epoch\n",
        ")\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ZhiDL7DyZKHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Fine-tuning w/ shift adjustment\n",
        "\n",
        "In this case, let's adjust atomic energy reference that are adequate for the *ab initio* calculation settings / software that are used for calculating our fine-tuning database.\n",
        "\n",
        "Following function `get_adjusted_shift` will run model from `cpt_path` on the database `data_paths`, and calculates proper (new) shift values"
      ],
      "metadata": {
        "id": "kO5kYnotWtJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "import sevenn.train.atoms_dataset as ad\n",
        "import sevenn.util as util\n",
        "\n",
        "\n",
        "def _linregress_while_converge(\n",
        "    total_energy_list, atomic_energy_list, atom_type_list, scale\n",
        "):\n",
        "    TOL = 1e-2\n",
        "    MAX_ITER = 1000\n",
        "\n",
        "    device = total_energy_list.device\n",
        "    reg_model = LinearRegression(fit_intercept=False)\n",
        "    contained_atom_types = atom_type_list.sum(dim=0) != 0\n",
        "    shift = torch.zeros(atom_type_list.shape[-1], device=device)\n",
        "    total_energy_list -= (scale * atomic_energy_list).sum(dim=1, keepdim=True)\n",
        "    for _ in range(MAX_ITER):\n",
        "        residual = \\\n",
        "            total_energy_list - (atom_type_list*shift).sum(dim=1, keepdim=True)\n",
        "        result = \\\n",
        "            reg_model.fit(atom_type_list.cpu().numpy(), residual.cpu().numpy())\n",
        "        delta = torch.tensor(result.coef_, device=device)[0]\n",
        "        delta[~contained_atom_types] = 0.\n",
        "        shift += delta\n",
        "        if torch.abs(delta).max() < TOL:\n",
        "            break\n",
        "\n",
        "    return shift\n",
        "\n",
        "\n",
        "def get_adjusted_shift(cpt_path, data_paths):\n",
        "    try:\n",
        "        model, config = util.model_from_checkpoint(cpt_path)\n",
        "    except:  # alias of pre-trained model (e.g. 7net-0)\n",
        "        cpt_path = util.pretrained_name_to_path(cpt_path)\n",
        "        model, config = util.model_from_checkpoint(cpt_path)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    del model.force_output\n",
        "    del model.rescale_atomic_energy, model.reduce_total_enegy\n",
        "    scale = torch.tensor(config['scale'], device=device)\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    dataset = ad.SevenNetAtomsDataset(\n",
        "        cutoff=config['cutoff'],\n",
        "        files=data_paths\n",
        "    )\n",
        "    loader = DataLoader(dataset=dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "    total_energy_list, atomic_energy_list, atom_type_list = [], [], []\n",
        "    total_species = len(config['_type_map'])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader):\n",
        "            batch = batch.to(device, non_blocking=True)\n",
        "            output = model(batch)\n",
        "\n",
        "            total_energy = output.total_energy.detach()\n",
        "            atom_type = output.atom_type.detach()\n",
        "            atomic_energy = output.scaled_atomic_energy.detach()\n",
        "            indices = batch.num_atoms.tolist()\n",
        "            total_ens = torch.unbind(total_energy)\n",
        "            atomic_energy = torch.split(atomic_energy.squeeze(-1), indices)\n",
        "            atom_types = torch.split(atom_type, indices)\n",
        "\n",
        "            for total_en, atomic_en, atom_type in zip(\n",
        "                total_ens, atomic_energy, atom_types\n",
        "            ):\n",
        "                total_energy_list.append(total_en)\n",
        "                atomic_en = torch.zeros(\n",
        "                    total_species,\n",
        "                    dtype=atomic_en.dtype,\n",
        "                    device=atomic_en.device,\n",
        "                ).scatter_reduce(\n",
        "                    0,\n",
        "                    atom_type,\n",
        "                    atomic_en,\n",
        "                    reduce='sum'\n",
        "                )\n",
        "                atomic_energy_list.append(atomic_en)\n",
        "\n",
        "                atom_type = torch.zeros(\n",
        "                    total_species,\n",
        "                    dtype=torch.long,\n",
        "                    device=atom_type.device\n",
        "                ).scatter_reduce(\n",
        "                    0,\n",
        "                    atom_type,\n",
        "                    torch.ones(\n",
        "                        atom_type.numel(),\n",
        "                        dtype=torch.long,\n",
        "                        device=atom_type.device\n",
        "                    ),\n",
        "                    reduce='sum'\n",
        "                )\n",
        "                atom_type_list.append(atom_type)\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "    total_energy_list = torch.vstack(total_energy_list)\n",
        "    atomic_energy_list = torch.vstack(atomic_energy_list)\n",
        "    atom_type_list = torch.vstack(atom_type_list)\n",
        "\n",
        "    return _linregress_while_converge(\n",
        "        total_energy_list, atomic_energy_list, atom_type_list, scale\n",
        "    )"
      ],
      "metadata": {
        "id": "Akray2cASvT_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's load the database (same with the case 1.)"
      ],
      "metadata": {
        "id": "MXUyL_ErfY9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from sevenn.train.graph_dataset import SevenNetGraphDataset\n",
        "import sevenn.util as util\n",
        "\n",
        "_, config = util.model_from_checkpoint(f'{prefix}/pretrained/checkpoint_small.pth')\n",
        "\n",
        "data_paths = [f'{prefix}/data/600K.extxyz', f'{prefix}/data/1200K.extxyz']\n",
        "dataset = SevenNetGraphDataset(\n",
        "    cutoff=config['cutoff'], files=data_paths, drop_info=False\n",
        ")\n",
        "num_dataset = len(dataset)\n",
        "num_train = int(num_dataset * 0.25)\n",
        "num_valid = 10\n",
        "\n",
        "dataset = dataset.shuffle()\n",
        "trainset = dataset[:num_train]\n",
        "validset = dataset[num_train:num_train + 10]\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "valid_loader = DataLoader(validset, batch_size=4)"
      ],
      "metadata": {
        "id": "EdKzobXTZTFp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run `get_adjusted_shift` to get proper shift values"
      ],
      "metadata": {
        "id": "WDIXQkDtffU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shift = get_adjusted_shift(\n",
        "    f'{prefix}/pretrained/checkpoint_small.pth', data_paths\n",
        ").tolist()"
      ],
      "metadata": {
        "id": "KF2kLeeOdksF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model from checkpoint.\n",
        "\n",
        "In this case, we change the shift value of the `rescale_atomic_energy` block to the proper value.\n",
        "\n",
        "Also, we may set shift and scale value trainable, which additionally help models to find proper shift values."
      ],
      "metadata": {
        "id": "ClWoXI-rfpNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sevenn.util as util\n",
        "from sevenn.nn.scale import SpeciesWiseRescale\n",
        "\n",
        "model, config = util.model_from_checkpoint(\n",
        "    f'{prefix}/pretrained/checkpoint_small.pth'\n",
        "  )\n",
        "\n",
        "# To enhance training speed, we will overwrite shift scale module to trainable\n",
        "# By making energy shift trainable, error quickly converges.\n",
        "shift_scale_module = model._modules['rescale_atomic_energy']\n",
        "scale = shift_scale_module.scale.tolist()\n",
        "\n",
        "model._modules['rescale_atomic_energy'] = SpeciesWiseRescale(\n",
        "    shift=shift,\n",
        "    scale=scale,\n",
        "    train_shift_scale=True,\n",
        ")"
      ],
      "metadata": {
        "id": "I-rIE3ekPqvg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting hyperparameters for the fine-tuning.\n",
        "\n",
        "Before we starts, let's save the initial checkpoint, which only changes shift values of the SevenNet-0-small.\n",
        "\n",
        "This checkpoint will not change underlying physics, but changes absolute energy values to the proper range."
      ],
      "metadata": {
        "id": "1wj_zix8gIWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "import torch.optim.lr_scheduler as scheduler\n",
        "\n",
        "from sevenn.error_recorder import ErrorRecorder\n",
        "from sevenn.train.trainer import Trainer\n",
        "\n",
        "\n",
        "config.update({\n",
        "    'optimizer': 'adam',\n",
        "    'optim_param': {'lr': 0.004},\n",
        "    'scheduler': 'linearlr',\n",
        "    'scheduler_param': {\n",
        "        'start_factor': 1.0, 'total_iters': 10, 'end_factor': 0.0001\n",
        "    },\n",
        "    'is_ddp': False,  # 7net-0 is traied with ddp=True.\n",
        "                      # We override this key False as we won't use it\n",
        "    'loss': 'huber',\n",
        "    'loss_param': {'delta': 0.01},\n",
        "    'force_loss_weight': 0.1,\n",
        "    'stress_loss_weight': 0.01,\n",
        "})\n",
        "trainer = Trainer.from_config(model, config)\n",
        "trainer.write_checkpoint(\n",
        "    f'{prefix}/checkpoint_shift.pth', config=config, epoch=0\n",
        ")\n",
        "\n",
        "train_recorder = ErrorRecorder.from_config(config)\n",
        "valid_recorder = deepcopy(train_recorder)"
      ],
      "metadata": {
        "id": "HO5LxzE-phWR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same scripts for the training."
      ],
      "metadata": {
        "id": "CnzMCVHTgp8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "\n",
        "from sevenn.logger import Logger\n",
        "\n",
        "\n",
        "valid_best = float('inf')\n",
        "total_epoch = 10\n",
        "\n",
        "# As error recorder is long, let's use sevennet_logger for pretty print\n",
        "# It is similar to outputs when using sevennet with terminal.\n",
        "with Logger(filename='log.sevenn', screen=True) as logger:\n",
        "  logger.greeting()  # prints ascii logo\n",
        "  for epoch in range(total_epoch):\n",
        "    logger.timer_start('epoch')\n",
        "    # trainer scans whole data from given loader,\n",
        "    # and updates error recorder with outputs.\n",
        "    trainer.run_one_epoch(\n",
        "        train_loader, is_train=True, error_recorder=train_recorder\n",
        "    )\n",
        "    trainer.run_one_epoch(\n",
        "        valid_loader, is_train=False, error_recorder=valid_recorder\n",
        "    )\n",
        "    trainer.scheduler_step()\n",
        "    train_err = train_recorder.epoch_forward()  # return averaged error & reset\n",
        "    valid_err = valid_recorder.epoch_forward()\n",
        "    logger.bar()\n",
        "    logger.writeline(\n",
        "        f'Epoch {epoch+1}/{total_epoch}  Learning rate: {trainer.get_lr()}'\n",
        "    )\n",
        "    logger.write_full_table([train_err, valid_err], ['Train', 'Valid'])\n",
        "    logger.timer_end('epoch', message=f'Epoch {epoch+1} elapsed')\n",
        "\n",
        "trainer.write_checkpoint(\n",
        "    f'{prefix}/checkpoint_fine_tuned_shift.pth',\n",
        "    config=config,\n",
        "    epoch=total_epoch\n",
        ")\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Z6n-qt9IppPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Application 1: Single-point calculation"
      ],
      "metadata": {
        "id": "NshdFrycacC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ASE` provides simulation interface for MLIPs using `Calculator` object in python.\n",
        "\n",
        "Many MLIP packages provides custom `Calculator` objects, including SevenNet\n",
        "\n",
        "SevenNet calculator can be obtained by followings:\n",
        "\n",
        "```\n",
        "from sevenn.calculator import SevenNetCalculator\n",
        "calc = SevenNetCalculator({checkpoint_path})\n",
        "...\n",
        "```\n",
        "\n",
        "for `checkpoint_path`, one should provide\n",
        "- Path / file name of generated checkpoint.pth file\n",
        "- Name of pretrained models (e.g., 7net-0)\n",
        "\n",
        "Further details using `Calculator` object can be found in `ASE` documentation\n",
        "\n",
        "(https://wiki.fysik.dtu.dk/ase/gettingstarted/tut01_molecule/molecule.html)\n",
        "\n",
        "In this example, let's calculate energy, force, stress of *ab initio* MD simulation trajectories of another supercell, and compare the accuracy with respect to the DFT.\n",
        "\n",
        "We have total 4 models.\n",
        "\n",
        "- 7net-0-small: Pretrained SevenNet\n",
        "- 7net-0-shift: 7net-0-small with adjusted shift\n",
        "- 7net-FT: Fine-tuned model from 7net-0-small\n",
        "- 7net-FT-shift: Fine-tuned model from 7net-0-shift"
      ],
      "metadata": {
        "id": "0-3fVI1Sax-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from ase.io import read\n",
        "from ase.units import bar\n",
        "\n",
        "from sevenn.calculator import SevenNetCalculator\n",
        "\n",
        "labels = ['7net-0-small', '7net-0-shift', '7net-FT', '7net-FT-shift']\n",
        "\n",
        "dft_energy, dft_forces, dft_stress = [], [], []\n",
        "mlip_energy_dct = {label: [] for label in labels}\n",
        "mlip_forces_dct = {label: [] for label in labels}\n",
        "mlip_stress_dct = {label: [] for label in labels}\n",
        "to_kBar = 1/bar/1000\n",
        "\n",
        "label_cpt_path_map = {\n",
        "    '7net-0-small': f'{prefix}/pretrained/checkpoint_small.pth',\n",
        "    '7net-0-shift': f'{prefix}/checkpoint_shift.pth',\n",
        "    '7net-FT': f'{prefix}/checkpoint_fine_tuned.pth',\n",
        "    '7net-FT-shift': f'{prefix}/checkpoint_fine_tuned_shift.pth',\n",
        "}\n",
        "\n",
        "traj = read(f'{prefix}/data/test_md.extxyz', ':')\n",
        "for atoms in tqdm(traj, desc='DFT'):\n",
        "    dft_energy.append(atoms.get_potential_energy() / len(atoms))\n",
        "    dft_forces.extend(atoms.get_forces().flatten())\n",
        "    dft_stress.extend(atoms.get_stress().flatten() * to_kBar)\n",
        "\n",
        "for label in labels:\n",
        "    calc = SevenNetCalculator(label_cpt_path_map[label])\n",
        "    for atoms in tqdm(traj, desc=label):\n",
        "        atoms.calc = calc\n",
        "        mlip_energy_dct[label].append(atoms.get_potential_energy() / len(atoms))\n",
        "        mlip_forces_dct[label].extend(atoms.get_forces().flatten())\n",
        "        mlip_stress_dct[label].extend(atoms.get_stress().flatten() * to_kBar)\n",
        "        atoms.calc = None\n",
        "    del calc"
      ],
      "metadata": {
        "id": "NQ-MIX8F4EkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot the correlation between DFT and each model on the single-point calculated energy, force, and stress."
      ],
      "metadata": {
        "id": "MBdtESt5l4Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "# draw a parity plot of energy / force / stress\n",
        "unit = {\"energy\": \"eV/atom\", \"force\": r\"eV/$\\rm{\\AA}$\", \"stress\": \"kbar\"}\n",
        "def density_colored_scatter_plot(\n",
        "    dft_energy,\n",
        "    nnp_energy,\n",
        "    dft_force,\n",
        "    nnp_force,\n",
        "    dft_stress,\n",
        "    nnp_stress,\n",
        "    title=None\n",
        "):\n",
        "    modes = ['energy', 'force', 'stress']\n",
        "    plt.figure(figsize=(18/2.54, 6/2.54))\n",
        "    for num, (x, y) in enumerate(\n",
        "        zip(\n",
        "            [dft_energy, dft_force, dft_stress],\n",
        "            [nnp_energy, nnp_force, nnp_stress]\n",
        "        )\n",
        "    ):\n",
        "        mode = modes[num]\n",
        "        idx = (\n",
        "            np.random.choice(len(x), 1000)\n",
        "            if len(x) > 1000\n",
        "            else list(range(len(x)))\n",
        "        )\n",
        "        xsam = [x[i] for i in idx]\n",
        "        ysam = [y[i] for i in idx]\n",
        "        xy = np.vstack([x, y])\n",
        "        xysam = np.vstack([xsam, ysam])\n",
        "        zsam = gaussian_kde(xysam)\n",
        "\n",
        "        z = zsam.pdf(xy)\n",
        "        idx = z.argsort()\n",
        "\n",
        "        x = [x[i] for i in idx]\n",
        "        y = [y[i] for i in idx]\n",
        "        z = [z[i] for i in idx]\n",
        "\n",
        "        ax = plt.subplot(int(f'13{num+1}'))\n",
        "        plt.scatter(x, y, c=z, s=4, cmap='plasma')\n",
        "\n",
        "        mini = min(min(x), min(y))\n",
        "        maxi = max(max(x), max(y))\n",
        "        ran = (maxi-mini) / 20\n",
        "        plt.plot(\n",
        "            [mini-ran, maxi+ran],\n",
        "            [mini-ran, maxi+ran],\n",
        "            color='grey',\n",
        "            linestyle='dashed'\n",
        "        )\n",
        "        plt.xlim(mini-ran, maxi+ran)\n",
        "        plt.ylim(mini-ran, maxi+ran)\n",
        "\n",
        "        plt.xlabel(f'DFT {mode} ({unit[mode]})')\n",
        "        plt.ylabel(f'MLP {mode} ({unit[mode]})')\n",
        "        ax.set_aspect('equal')\n",
        "        if title:\n",
        "          ax.set_title(f'{title} {mode}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "for label in labels:\n",
        "    density_colored_scatter_plot(\n",
        "        dft_energy,\n",
        "        mlip_energy_dct[label],\n",
        "        dft_forces,\n",
        "        mlip_forces_dct[label],\n",
        "        dft_stress,\n",
        "        mlip_stress_dct[label],\n",
        "        label,\n",
        "    )"
      ],
      "metadata": {
        "id": "VuwZdsqe4OOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Application 2: Geometric relaxation\n",
        "\n",
        "From now on, we will utilize 7net-FT-shift as a base model.\n",
        "\n",
        "Geometric relaxation is a task that finds the local energy minimum at given potential energy surface (PES) near the initial configuration.\n",
        "\n",
        "This can be done by using ASE modules, combining `Optimizer`, `Filter` and `Calculator` object.\n",
        "\n",
        "- `Optimizer` gives the algorithm for energy minimization\n",
        "- `Filter` gives more advanced feature of relaxation (e.g, relax both atomic position and cell size, ISIF=3 in VASP)\n",
        "- `Calculator` gives PES, just like described in Appl. 1.\n",
        "\n",
        "For more information, please check:\n",
        "\n",
        "https://wiki.fysik.dtu.dk/ase/ase/optimize.html\n",
        "\n",
        "https://wiki.fysik.dtu.dk/ase/ase/filters.html\n",
        "\n",
        "First, let's call the SevenNetCalculator."
      ],
      "metadata": {
        "id": "cR5LQgbZmMM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sevenn.calculator import SevenNetCalculator\n",
        "\n",
        "\n",
        "calc = SevenNetCalculator(f'{prefix}/checkpoint_fine_tuned_shift.pth')"
      ],
      "metadata": {
        "id": "H55-gzOrnkkW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can relax a Argyrodite supercell."
      ],
      "metadata": {
        "id": "N3EM5O5UqBS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "from ase.io import read, write, Trajectory\n",
        "from ase.optimize import LBFGS  # Optimizer\n",
        "from ase.filters import FrechetCellFilter  # Filter\n",
        "\n",
        "atoms = read(f'{prefix}/data/test_md.extxyz', 0)\n",
        "atoms.calc = calc\n",
        "\n",
        "cf = FrechetCellFilter(atoms, hydrostatic_strain=True)\n",
        "opt = LBFGS(cf, trajectory=f'{prefix}/relax.traj')\n",
        "opt.run(fmax=0.05, steps=1000)\n",
        "\n",
        "traj = Trajectory(f'{prefix}/relax.traj')\n",
        "possible = []\n",
        "for i in range(len(traj)):\n",
        "    try:\n",
        "        possible.append(traj[i])\n",
        "    except:\n",
        "        pass\n",
        "write(f'{prefix}/relax.gif', possible[::10])\n",
        "write(f'{prefix}/relax.extxyz', atoms)\n",
        "\n",
        "vol = atoms.get_cell().volume / 8 # 222 supercell\n",
        "print(f'Relaxed volume per unit cell = {vol} Å³')\n",
        "print(f'Experimental volume per unit cell = 956 - 960 Å³')\n",
        "\n",
        "Image(open(f'{prefix}/relax.gif', 'rb').read())"
      ],
      "metadata": {
        "id": "LaG45lVopzaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Application 3: NVT MD simulation\n",
        "\n",
        "From relaxed geometries, let's run MD simulation at constant temperature and volume.\n",
        "\n",
        "In ASE, they provide various NVT ensembls, such as Langevin, Nose-Hoover, and etc.\n",
        "\n",
        "For more information please follow:\n",
        "\n",
        "https://wiki.fysik.dtu.dk/ase/ase/md.html\n",
        "\n",
        "Here, we will run Langevin dynamics at 600 K.\n",
        "\n",
        "While MD, let's check the diffusivity of each atoms.\n"
      ],
      "metadata": {
        "id": "smJaVqPt7m9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "import numpy as np\n",
        "\n",
        "from ase.io import read\n",
        "from ase import units\n",
        "from ase.md import MDLogger\n",
        "from ase.md.langevin import Langevin\n",
        "\n",
        "from sevenn.calculator import SevenNetCalculator\n",
        "\n",
        "\n",
        "calc = SevenNetCalculator(f'{prefix}/checkpoint_fine_tuned_shift.pth')\n",
        "atoms = read(f'{prefix}/relax.extxyz')\n",
        "atoms.calc = calc\n",
        "atoms.set_momenta(\n",
        "    np.random.normal(\n",
        "        scale=np.sqrt(units.kB * 600 * atoms.get_masses()[:, None]),\n",
        "        size=(len(atoms), 3)\n",
        "    )\n",
        ")\n",
        "timestep = 2 * units.fs  # 1 femtosecond\n",
        "friction = 0.01 / units.fs  # Friction coefficient\n",
        "dyn = Langevin(\n",
        "    atoms,\n",
        "    timestep,\n",
        "    trajectory=f'{prefix}/nvt_md.traj',\n",
        "    temperature_K=600,\n",
        "    friction=friction\n",
        ")\n",
        "\n",
        "logger = MDLogger(dyn, atoms, '-', header=True, stress=True, peratom=True)\n",
        "dyn.attach(logger, interval=10)\n",
        "dyn.run(1000)"
      ],
      "metadata": {
        "id": "5F2UFGoY7i0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ase.io import write, Trajectory\n",
        "\n",
        "\n",
        "traj = Trajectory(f'{prefix}/nvt_md.traj')\n",
        "possible = []\n",
        "for i in range(len(traj)):\n",
        "    try:\n",
        "        possible.append(traj[i])\n",
        "    except:\n",
        "        pass\n",
        "write(f'{prefix}/nvt_md.gif', possible[::50])\n",
        "\n",
        "Image(open(f'{prefix}/nvt_md.gif', 'rb').read())"
      ],
      "metadata": {
        "id": "A8YnzJhDLTdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from ase.io import write, Trajectory\n",
        "\n",
        "\n",
        "traj = Trajectory(f'{prefix}/nvt_md.traj')\n",
        "possible = []\n",
        "for i in range(len(traj)):\n",
        "    try:\n",
        "        possible.append(traj[i])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "init = possible[0]\n",
        "init_pos = init.get_positions()\n",
        "elem_types = np.array(init.get_chemical_symbols())\n",
        "\n",
        "elems = ['Li', 'P', 'S', 'Cl']\n",
        "msd = {elem: [0] for elem in elems}\n",
        "time = [0]\n",
        "\n",
        "for timestep, atoms in enumerate(possible):\n",
        "    time.append(timestep*2/1000) # in ps\n",
        "    for elem in elems:\n",
        "        init = init_pos[elem_types==elem]\n",
        "        pos = atoms.get_positions()[elem_types==elem]\n",
        "        msd[elem].append(np.mean(np.square(init-pos)))\n",
        "\n",
        "color = {\n",
        "    'Li': (204/255, 128/255, 1),\n",
        "    'P': (1, 128/255, 0),\n",
        "    'S': (1, 1, 48/255),\n",
        "    'Cl': (31/255, 240/255, 31/255),\n",
        "}\n",
        "\n",
        "plt.figure()\n",
        "for elem in elems:\n",
        "    plt.plot(time, msd[elem], color=color[elem], label=elem)\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('Time (ps)')\n",
        "plt.ylabel('MSD (Å²)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "emQ7gNH2O60N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}